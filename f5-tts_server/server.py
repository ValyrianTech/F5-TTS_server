import os
import time
import torch
from fastapi import FastAPI, UploadFile, File, HTTPException, Form
from fastapi.middleware.cors import CORSMiddleware
from starlette.responses import StreamingResponse
from typing import Optional
from pydantic import BaseModel
import logging
import io
import magic
from f5_tts.api import F5TTS

logging.basicConfig(level=logging.INFO)

app = FastAPI()

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allows all origins
    allow_credentials=True,
    allow_methods=["*"],  # Allows all methods
    allow_headers=["*"],  # Allows all headers
)

device = "cuda:0" if torch.cuda.is_available() else "cpu"

# Initialize F5-TTS model
model = F5TTS(device=device)

output_dir = 'outputs'
os.makedirs(output_dir, exist_ok=True)
os.makedirs("resources", exist_ok=True)

class UploadAudioRequest(BaseModel):
    audio_file_label: str

@app.on_event("startup")
async def startup_event():
    test_text = "This is a test sentence generated by the F5-TTS API."
    voice = "demo_speaker0"
    await synthesize_speech(test_text, voice)

@app.get("/base_tts/")
async def base_tts(text: str, accent: Optional[str] = 'en-newest', speed: Optional[float] = 1.0):
    """
    Perform text-to-speech conversion using only the base speaker.
    """
    try:
        save_path = f'{output_dir}/output_base.wav'
        # Use a default reference audio for base TTS
        ref_file = os.path.join("resources", "base_speaker.wav")
        if not os.path.exists(ref_file):
            # If no base speaker exists, use the example from F5-TTS
            from importlib.resources import files
            ref_file = str(files("f5_tts").joinpath("infer/examples/basic/basic_ref_en.wav"))
            ref_text = "some call me nature, others call me mother nature."
        else:
            ref_text = "This is a reference text for the base speaker."

        wav, sr, _ = model.infer(
            ref_file=ref_file,
            ref_text=ref_text,
            gen_text=text,
            speed=speed,
            file_wave=save_path
        )
        
        result = StreamingResponse(open(save_path, 'rb'), media_type="audio/wav")
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/change_voice/")
async def change_voice(reference_speaker: str = Form(...), file: UploadFile = File(...), watermark: Optional[str] = "@F5-TTS"):
    """
    Change the voice of an existing audio file.
    """
    try:
        logging.info(f'changing voice to {reference_speaker}...')

        contents = await file.read()
        temp_file = io.BytesIO(contents)
        
        # Save the input audio temporarily
        input_path = f'{output_dir}/input_audio.wav'
        with open(input_path, 'wb') as f:
            f.write(contents)

        # Find the reference audio file
        matching_files = [file for file in os.listdir("resources") if file.startswith(str(reference_speaker))]
        if not matching_files:
            raise HTTPException(status_code=400, detail="No matching reference speaker found.")
        
        reference_file = f'resources/{matching_files[0]}'
        
        # For voice conversion, we'll use the same text for both reference and generation
        # This helps maintain the timing and prosody
        text = model.transcribe(input_path)
        save_path = f'{output_dir}/output_converted.wav'

        wav, sr, _ = model.infer(
            ref_file=reference_file,
            ref_text=text,
            gen_text=text,
            file_wave=save_path
        )

        result = StreamingResponse(open(save_path, 'rb'), media_type="audio/wav")
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upload_audio/")
async def upload_audio(audio_file_label: str = Form(...), file: UploadFile = File(...)):
    """
    Upload an audio file for later use as the reference audio.
    """
    try:
        contents = await file.read()

        allowed_extensions = {'wav', 'mp3', 'flac', 'ogg'}
        max_file_size = 5 * 1024 * 1024  # 5MB

        if not file.filename.split('.')[-1] in allowed_extensions:
            return {"error": "Invalid file type. Allowed types are: wav, mp3, flac, ogg"}

        if len(contents) > max_file_size:
            return {"error": "File size is over limit. Max size is 5MB."}

        temp_file = io.BytesIO(contents)
        file_format = magic.from_buffer(temp_file.read(), mime=True)

        if 'audio' not in file_format:
            return {"error": "Invalid file content."}

        file_extension = file.filename.split('.')[-1]
        stored_file_name = f"{audio_file_label}.{file_extension}"

        with open(f"resources/{stored_file_name}", "wb") as f:
            f.write(contents)

        return {"message": f"File {file.filename} uploaded successfully with label {audio_file_label}."}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/synthesize_speech/")
async def synthesize_speech(
        text: str,
        voice: str,
        accent: Optional[str] = 'en-newest',
        speed: Optional[float] = 1.0,
        watermark: Optional[str] = "@F5-TTS"
):
    """
    Synthesize speech from text using a specified voice and style.
    """
    start_time = time.time()
    try:
        logging.info(f'Generating speech for {voice}')
        if watermark:
            logging.info(f'watermark: {watermark}')

        # Retrieve the correct file based on the 'voice' parameter
        matching_files = [file for file in os.listdir("resources") if file.startswith(voice)]

        if not matching_files:
            raise HTTPException(status_code=400, detail="No matching voice found.")

        reference_file = f'resources/{matching_files[0]}'
        
        # Get the reference text through transcription
        ref_text = model.transcribe(reference_file)
        save_path = f'{output_dir}/output_synthesized.wav'

        wav, sr, _ = model.infer(
            ref_file=reference_file,
            ref_text=ref_text,
            gen_text=text,
            speed=speed,
            file_wave=save_path
        )

        result = StreamingResponse(open(save_path, 'rb'), media_type="audio/wav")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

    end_time = time.time()
    elapsed_time = end_time - start_time

    result.headers["X-Elapsed-Time"] = str(elapsed_time)
    result.headers["X-Device-Used"] = device

    # Add CORS headers
    result.headers["Access-Control-Allow-Origin"] = "*"
    result.headers["Access-Control-Allow-Credentials"] = "true"
    result.headers["Access-Control-Allow-Headers"] = "Origin, Content-Type, X-Amz-Date, Authorization, X-Api-Key, X-Amz-Security-Token, locale"
    result.headers["Access-Control-Allow-Methods"] = "POST, OPTIONS"

    return result
